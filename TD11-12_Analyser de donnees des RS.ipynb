{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecte, Traitement, et Analyse de données de réseaux sociaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du fichier Json et nettoyage du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goumin des éléphants joueurs la même fatigue même twitter225\n",
      " ericbailly24 maxigr04del mes tontons vous avez fait votre part JO prochain on ira en demi final au moins BRAVO à vous SupportriceMazo domie CIV\n",
      "Ah oui le sommeil là sera compliqué CIV est éliminé des JO Ahi on peut faire ça \n",
      "31 juillet journée internationale de la femme africaine jifa\n",
      "Le pedigree https t co D3Rv7A2BOF\n",
      " isabelle170516 leonna julie Steiner2502 Vous avez tt à fait raison le silence incompréhensible du gouver noument et des merdias sur ce très important et dramatique sujet prouve de manière irréfutable leur implication à ce plan diabolique maquillé \n",
      " LynLyna12 leonna julie La grande muette continue et continuera de le rester À part quelques irréductibles à la retraite \n",
      "Under wsh \n",
      "Les bains d apollon versailles nocturne appollon à Château de Versailles https t co SFGXP06r61\n",
      " leonna julie Le rdv aujourd hui aura tenu ses promesses Pour les problèmes de sommeil 1 cachet à la mélatonine 1 80 mg et je dors comme un bébé Réveil en pleine forme assuré Et sans acoutumances pas comme avec ces béquilles chimiques Bonne soirée Julie https t co F6zvVfWwAf\n",
      " miliemelo82 kilianbridoux LeMeneec il est temps de laisser mijoter\n",
      " Polo82810715 lrestistant73 Un mouton c est bien plus intelligent que toi \n",
      "I m at Gardens of Versailles in Versailles Île de France https t co fG7Q40cjWk\n",
      "Jungle Cruise https t co JyM8WQjz4p UGC Cyrano in Versailles Île de France https t co ts0FrwWU8W\n",
      " Pauluskupa \n",
      " anniemacmanus legend \n",
      " yebbasmith anniemacmanus \n",
      "Vient de publier une photo à Quelquepart https t co fWNqGJosAA\n",
      " AzmiAnees3 He was my lover s accomplice \n",
      "Le gardien lui parle non https t co e3WewDSQOJ\n"
     ]
    }
   ],
   "source": [
    "#Ouverture du fichier jason\n",
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "#Effacer tous les caractères spéciaux dans le texte\n",
    "\n",
    "for dict in data_dict:\n",
    "    #print (dict[\"text\"], end = '\\n')\n",
    "    dict[\"text\"] = re.sub(r'[\\W_]+',' ', dict[\"text\"])\n",
    "    print(dict[\"text\"])\n",
    "\n",
    "# Création et écriture dans le fichier zone d'atterissage\n",
    "with open(\"zone_d'atterrissage.json\", 'w') as f2:\n",
    "    json.dump(data_dict, f2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##c'est la même chose que ce que j'ai fait juste en haut mais j'ai essayé de faire une \n",
    "# copie du dictionnaire pour pouvoir faire des modifs sans que le dictionnaire \n",
    "# initial ne soit modifier pour pouvoir le réutiliser après, mais ça ne marche pas\n",
    "\n",
    "#Ouverture du fichier jason\n",
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "#Effacer tous les caractères spéciaux dans le texte\n",
    "copy_data = data_dict.copy()\n",
    "print(copy_data)\n",
    "for dict in copy_data:\n",
    "    #print (dict[\"text\"], end = '\\n')\n",
    "    copy_data[\"text\"] = re.sub(r'[\\W_]+',' ', copy_data[\"text\"])\n",
    "\n",
    "\n",
    "# Création et écriture dans le fichier zone d'atterissage\n",
    "with open(\"zone_d'atterrissage.json\", 'w') as f2:\n",
    "    json.dump(copy_data, f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification de l'auteur de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1421616335700824064', '1421599703116943360', '1421599163561742339', '1421591889095057416', '1421582795294617605', '1421581383454052359', '1421575939700445184', '1421569996858269697', '1421563798503272448', '1421562928176803848', '1421560592775761923', '1421558089761935365', '1421551384512585729', '1421550148061212673', '1421547651171078146', '1421499497620836356', '1421499329974579200', '1421487092023050244', '1421472953980571651', '1421429486432686081']\n"
     ]
    }
   ],
   "source": [
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "liste_auteurs= []\n",
    "for dict in data:\n",
    "    liste_auteurs.append(dict['_id'])\n",
    "print(liste_auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de la liste des hashtags et la liste des mentions de chaque publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#twitter225', '#SupportriceMazo', '#domie', '#CIV', '#CIV', '#jifa', '#versailles', '#nocturne', '#appollon']\n",
      "\n",
      "\n",
      "['@ericbailly24', '@maxigr04del', '@isabelle170516', '@leonna_julie', '@Steiner2502', '@LynLyna12', '@leonna_julie', '@leonna_julie', '@miliemelo82', '@kilianbridoux', '@LeMeneec', '@Polo82810715', '@lrestistant73', '@Pauluskupa', '@anniemacmanus', '@yebbasmith', '@anniemacmanus', '@AzmiAnees3']\n"
     ]
    }
   ],
   "source": [
    "hash = []\n",
    "mention = []\n",
    "\n",
    "for dict in data:\n",
    "    #Extraction des hashtags\n",
    "    hashtags = re.findall(r'\\B#\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    hash.append(hashtags)\n",
    "    #Extraction des mentions\n",
    "    mentions = re.findall(r'\\B@\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    mention.append(mentions)\n",
    "\n",
    "liste_hashtags = []\n",
    "for i in range (len(hash)):\n",
    "    for e in hash[i]:\n",
    "        liste_hashtags.append(e)\n",
    "liste_mentions = []\n",
    "\n",
    "for i in range (len(mention)):\n",
    "    for e in mention[i]:\n",
    "        liste_mentions.append(e)\n",
    "\n",
    "\n",
    "print(liste_hashtags)\n",
    "print('\\n')\n",
    "print(liste_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de sentiments de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "liste_sentiments = []\n",
    "with open(\"zone_d'atterrissage.json\") as f:\n",
    "   clean_data  = json.load(f)\n",
    "\n",
    "for dico in clean_data:\n",
    "    sentiment = TextBlob(dico['text']).sentiment \n",
    "    liste_sentiments.append(sentiment[1])\n",
    "print(liste_sentiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification du/des topics de la publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dictionnaire contenant un hashtag et le nombre de fois qu'il apparaît\n",
    "def K_hashtags(liste_hashtags):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste_hashtags)):\n",
    "            dic[liste_hashtags[i]] = liste_hashtags.count(liste_hashtags[i]) \n",
    "    return dic\n",
    "\n",
    "K_hashtags(liste_hashtags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateurs mentionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il est mentionné\n",
    "\n",
    "def K_mention(liste_mentions):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste_mentions)):\n",
    "            dic[liste_mentions[i]] = liste_mentions.count(liste_mentions[i]) \n",
    "    return dic\n",
    "\n",
    "K_mention(liste_mentions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il a posté un tweet\n",
    "def K_utilisateur(liste_auteurs):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste_auteurs)):\n",
    "            dic[liste_auteurs[i]] = liste_auteurs.count(liste_auteurs[i]) \n",
    "    return dic\n",
    "\n",
    "K_utilisateur(liste_auteurs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "530acc480c6cf79cacfe3b795deb12112f40cf157cab9e2841c7338651ce5f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
