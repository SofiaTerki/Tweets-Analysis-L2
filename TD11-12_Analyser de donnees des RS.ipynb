{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecte, Traitement, et Analyse de données de réseaux sociaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du fichier Json et nettoyage du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouverture du fichier jason\n",
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "#Effacer tous les caractères spéciaux dans le texte et récupérer le texte propre dans une liste\n",
    "liste_txt =[]\n",
    "for dict in data_dict:\n",
    "    dict[\"text\"] = re.sub(r'[\\W_]+',' ', dict[\"text\"])\n",
    "    liste_txt.append(dict['text'])\n",
    "\n",
    "# Création et écriture dans le fichier zone d'atterissage\n",
    "with open(\"zone_d'atterrissage.json\", 'w') as f2:\n",
    "    json.dump(data_dict, f2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification de l'auteur de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1339914264522461187', '1339914264522461187', '1339914264522461187', '1339914264522461187', '717025418', '992904738516717570', '992904738516717570', '736523371', '1471684208', '992904738516717570', '3169236915', '992904738516717570', '16267684', '60117154', '3169236915', '372993152', '372993152', '105241852', '2357913366', '717025418']\n"
     ]
    }
   ],
   "source": [
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "liste_auteurs= []\n",
    "for dict in data:\n",
    "    liste_auteurs.append(dict['author_id'])\n",
    "print(liste_auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de la liste des hashtags et la liste des mentions de chaque publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#twitter225'], ['#SupportriceMazo', '#domie', '#CIV'], ['#CIV'], ['#jifa'], [], [], [], [], ['#versailles', '#nocturne', '#appollon'], [], [], [], [], [], [], [], [], [], [], []]\n",
      "[[], ['@ericbailly24', '@maxigr04del'], [], [], [], ['@isabelle170516', '@leonna_julie', '@Steiner2502'], ['@LynLyna12', '@leonna_julie'], [], [], ['@leonna_julie'], ['@miliemelo82', '@kilianbridoux', '@LeMeneec'], ['@Polo82810715', '@lrestistant73'], [], [], ['@Pauluskupa'], ['@anniemacmanus'], ['@yebbasmith', '@anniemacmanus'], [], ['@AzmiAnees3'], []]\n"
     ]
    }
   ],
   "source": [
    "liste_hashtags = []\n",
    "liste_mentions = []\n",
    "\n",
    "for dict in data:\n",
    "    #Extraction des hashtags\n",
    "    hashtags = re.findall(r'\\B#\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_hashtags.append(hashtags)\n",
    "    #Extraction des mentions\n",
    "    mentions = re.findall(r'\\B@\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_mentions.append(mentions)\n",
    "\n",
    "print(liste_hashtags)\n",
    "\n",
    "print(liste_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de sentiments de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "liste_sentiments = []\n",
    "with open(\"zone_d'atterrissage.json\") as f:\n",
    "   clean_data  = json.load(f)\n",
    "   \n",
    "for dico in clean_data:\n",
    "    sentiment = TextBlob(dico['text']).sentiment \n",
    "    liste_sentiments.append(sentiment[1])\n",
    "print(liste_sentiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification du/des topics de la publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politique', 'sport', 'humour', 'sport', 'politique', 'humour', 'sport', 'politique', 'humour', 'culture', 'politique', 'sport', 'politique', 'humour', 'humour', 'culture', 'culture', 'sport', 'sport', 'humour']\n"
     ]
    }
   ],
   "source": [
    "# On va attribuer des topics aléatoirement \n",
    "liste_topics = ['sport', 'politique', 'culture', 'humour']\n",
    "publication_topics = [rd.choice(liste_topics) for i in range(len(liste_auteurs))]\n",
    "print(publication_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du DataFrame à exploiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Texte</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>Goumin des éléphants joueurs la même fatigue m...</td>\n",
       "      <td>#twitter225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>ericbailly24 maxigr04del mes tontons vous ave...</td>\n",
       "      <td>#SupportriceMazo</td>\n",
       "      <td>@ericbailly24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>Ah oui le sommeil là sera compliqué CIV est él...</td>\n",
       "      <td>#CIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>31 juillet journée internationale de la femme ...</td>\n",
       "      <td>#jifa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717025418</td>\n",
       "      <td>Le pedigree https t co D3Rv7A2BOF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>isabelle170516 leonna julie Steiner2502 Vous ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@isabelle170516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>LynLyna12 leonna julie La grande muette conti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@LynLyna12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>736523371</td>\n",
       "      <td>Under wsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1471684208</td>\n",
       "      <td>Les bains d apollon versailles nocturne appoll...</td>\n",
       "      <td>#versailles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>leonna julie Le rdv aujourd hui aura tenu ses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@leonna_julie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3169236915</td>\n",
       "      <td>miliemelo82 kilianbridoux LeMeneec il est tem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@miliemelo82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>Polo82810715 lrestistant73 Un mouton c est bi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Polo82810715</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16267684</td>\n",
       "      <td>I m at Gardens of Versailles in Versailles Île...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60117154</td>\n",
       "      <td>Jungle Cruise https t co JyM8WQjz4p UGC Cyrano...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3169236915</td>\n",
       "      <td>Pauluskupa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Pauluskupa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>372993152</td>\n",
       "      <td>anniemacmanus legend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@anniemacmanus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>372993152</td>\n",
       "      <td>yebbasmith anniemacmanus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@yebbasmith</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>105241852</td>\n",
       "      <td>Vient de publier une photo à Quelquepart https...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2357913366</td>\n",
       "      <td>AzmiAnees3 He was my lover s accomplice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@AzmiAnees3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>717025418</td>\n",
       "      <td>Le gardien lui parle non https t co e3WewDSQOJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                              Texte  \\\n",
       "0   1339914264522461187  Goumin des éléphants joueurs la même fatigue m...   \n",
       "1   1339914264522461187   ericbailly24 maxigr04del mes tontons vous ave...   \n",
       "2   1339914264522461187  Ah oui le sommeil là sera compliqué CIV est él...   \n",
       "3   1339914264522461187  31 juillet journée internationale de la femme ...   \n",
       "4             717025418                  Le pedigree https t co D3Rv7A2BOF   \n",
       "5    992904738516717570   isabelle170516 leonna julie Steiner2502 Vous ...   \n",
       "6    992904738516717570   LynLyna12 leonna julie La grande muette conti...   \n",
       "7             736523371                                         Under wsh    \n",
       "8            1471684208  Les bains d apollon versailles nocturne appoll...   \n",
       "9    992904738516717570   leonna julie Le rdv aujourd hui aura tenu ses...   \n",
       "10           3169236915   miliemelo82 kilianbridoux LeMeneec il est tem...   \n",
       "11   992904738516717570   Polo82810715 lrestistant73 Un mouton c est bi...   \n",
       "12             16267684  I m at Gardens of Versailles in Versailles Île...   \n",
       "13             60117154  Jungle Cruise https t co JyM8WQjz4p UGC Cyrano...   \n",
       "14           3169236915                                        Pauluskupa    \n",
       "15            372993152                              anniemacmanus legend    \n",
       "16            372993152                          yebbasmith anniemacmanus    \n",
       "17            105241852  Vient de publier une photo à Quelquepart https...   \n",
       "18           2357913366           AzmiAnees3 He was my lover s accomplice    \n",
       "19            717025418     Le gardien lui parle non https t co e3WewDSQOJ   \n",
       "\n",
       "            Hashtags         Mentions  Sentiments     Topics  \n",
       "0        #twitter225              NaN         0.0  politique  \n",
       "1   #SupportriceMazo    @ericbailly24         1.0      sport  \n",
       "2               #CIV              NaN         0.0     humour  \n",
       "3              #jifa              NaN         0.0      sport  \n",
       "4                NaN              NaN         0.0  politique  \n",
       "5                NaN  @isabelle170516         1.0     humour  \n",
       "6                NaN       @LynLyna12         0.0      sport  \n",
       "7                NaN              NaN         0.0  politique  \n",
       "8        #versailles              NaN         0.0     humour  \n",
       "9                NaN    @leonna_julie         0.0    culture  \n",
       "10               NaN     @miliemelo82         0.0  politique  \n",
       "11               NaN    @Polo82810715         0.9      sport  \n",
       "12               NaN              NaN         0.0  politique  \n",
       "13               NaN              NaN         0.0     humour  \n",
       "14               NaN      @Pauluskupa         0.0     humour  \n",
       "15               NaN   @anniemacmanus         0.0    culture  \n",
       "16               NaN      @yebbasmith         0.0    culture  \n",
       "17               NaN              NaN         0.0      sport  \n",
       "18               NaN      @AzmiAnees3         0.0      sport  \n",
       "19               NaN              NaN         0.0     humour  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploitation = pd.DataFrame(list(zip(liste_auteurs,liste_txt, liste_hashtags, liste_mentions, liste_sentiments, publication_topics)), columns = ['ID', 'Texte','Hashtags', 'Mentions', 'Sentiments', 'Topics'])\n",
    "df_exploitation['Hashtags'] = df_exploitation['Hashtags'].str.get(0)\n",
    "df_exploitation['Mentions'] = df_exploitation['Mentions'].str.get(0)\n",
    "df_exploitation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dictionnaire contenant un hashtag et le nombre de fois qu'il apparaît\n",
    "def K_hashtags(liste_hashtags):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste_hashtags)):\n",
    "            dic[liste_hashtags[i]] = liste_hashtags.count(liste_hashtags[i]) \n",
    "    return dic\n",
    "\n",
    "K_hashtags(liste_hashtags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateurs mentionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il est mentionné\n",
    "\n",
    "def K_mention(liste_mentions):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste_mentions)):\n",
    "            dic[liste_mentions[i]] = liste_mentions.count(liste_mentions[i]) \n",
    "    return dic\n",
    "\n",
    "K_mention(liste_mentions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il a posté un tweet\n",
    "def K_utilisateur(liste_auteurs):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste_auteurs)):\n",
    "            dic[liste_auteurs[i]] = liste_auteurs.count(liste_auteurs[i]) \n",
    "    return dic\n",
    "\n",
    "K_utilisateur(liste_auteurs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "530acc480c6cf79cacfe3b795deb12112f40cf157cab9e2841c7338651ce5f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
