{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecte, Traitement, et Analyse de données de réseaux sociaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du fichier Json et nettoyage du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouverture du fichier jason\n",
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "#Effacer tous les caractères spéciaux dans le texte et récupérer le texte propre dans une liste\n",
    "liste_txt =[]\n",
    "for dict in data_dict:\n",
    "    dict[\"text\"] = re.sub(r'[\\W_]+',' ', dict[\"text\"])\n",
    "    liste_txt.append(dict['text'])\n",
    "\n",
    "# Création et écriture dans le fichier zone d'atterissage\n",
    "with open(\"zone_d'atterrissage.json\", 'w') as f2:\n",
    "    json.dump(data_dict, f2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification de l'auteur de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1339914264522461187', '1339914264522461187', '1339914264522461187', '1339914264522461187', '717025418', '992904738516717570', '992904738516717570', '736523371', '1471684208', '992904738516717570', '3169236915', '992904738516717570', '16267684', '60117154', '3169236915', '372993152', '372993152', '105241852', '2357913366', '717025418']\n"
     ]
    }
   ],
   "source": [
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "liste_auteurs= []\n",
    "for dict in data:\n",
    "    liste_auteurs.append(dict['author_id'])\n",
    "print(liste_auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de la liste des hashtags et la liste des mentions de chaque publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#twitter225'], ['#SupportriceMazo', '#domie', '#CIV'], ['#CIV'], ['#jifa'], [], [], [], [], ['#versailles', '#nocturne', '#appollon'], [], [], [], [], [], [], [], [], [], [], []]\n",
      "[[], ['@ericbailly24', '@maxigr04del'], [], [], [], ['@isabelle170516', '@leonna_julie', '@Steiner2502'], ['@LynLyna12', '@leonna_julie'], [], [], ['@leonna_julie'], ['@miliemelo82', '@kilianbridoux', '@LeMeneec'], ['@Polo82810715', '@lrestistant73'], [], [], ['@Pauluskupa'], ['@anniemacmanus'], ['@yebbasmith', '@anniemacmanus'], [], ['@AzmiAnees3'], []]\n"
     ]
    }
   ],
   "source": [
    "liste_hashtags = []\n",
    "liste_mentions = []\n",
    "\n",
    "for dict in data:\n",
    "    #Extraction des hashtags\n",
    "    hashtags = re.findall(r'\\B#\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_hashtags.append(hashtags)\n",
    "    #Extraction des mentions\n",
    "    mentions = re.findall(r'\\B@\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_mentions.append(mentions)\n",
    "\n",
    "print(liste_hashtags)\n",
    "\n",
    "print(liste_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de sentiments de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "liste_sentiments = []\n",
    "with open(\"zone_d'atterrissage.json\") as f:\n",
    "   clean_data  = json.load(f)\n",
    "   \n",
    "for dico in clean_data:\n",
    "    sentiment = TextBlob(dico['text']).sentiment \n",
    "    liste_sentiments.append(sentiment[1])\n",
    "print(liste_sentiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification du/des topics de la publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['culture', 'humour', 'humour', 'sport', 'politique', 'politique', 'culture', 'humour', 'culture', 'sport', 'politique', 'sport', 'humour', 'humour', 'politique', 'humour', 'sport', 'humour', 'sport', 'culture']\n"
     ]
    }
   ],
   "source": [
    "# On va attribuer des topics aléatoirement \n",
    "liste_topics = ['sport', 'politique', 'culture', 'humour']\n",
    "twitts_topics = [rd.choice(liste_topics) for i in range(len(liste_auteurs))]\n",
    "print(twitts_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du DataFrame à exploiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploitation = pd.DataFrame(list(zip(liste_auteurs,liste_txt, liste_hashtags, liste_mentions, liste_sentiments, twitts_topics)), columns = ['ID', 'Texte','Hashtags', 'Mentions', 'Sentiments', 'Topics'])\n",
    "df_exploitation\n",
    "\n",
    "# sauvegarder notre DataFrame dans un fichier csv\n",
    "df_exploitation.to_csv(\"zone_d'exploitation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#twitter225': 1,\n",
       " '#SupportriceMazo': 1,\n",
       " '#domie': 1,\n",
       " '#CIV': 2,\n",
       " '#jifa': 1,\n",
       " '#versailles': 1,\n",
       " '#nocturne': 1,\n",
       " '#appollon': 1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''création d'un dictionnaire contenant un hashtag et le nombre de fois qu'il apparaît'''\n",
    "liste_hash = [x for elem in liste_hashtags for x in elem] \n",
    "def occurence_hashtag(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "occurence_hashtag(liste_hash)\n",
    "dico1=occurence_hashtag(liste_hash)\n",
    "#print(dico1)\n",
    "\n",
    "'''creation d'un top K hashtag'''\n",
    "    # si k =3 alors affiche les 3 premiers hashtags les plus utilisés dans l'ordre --> le top 3\n",
    "\n",
    "def topK_hashtag(dico,K):\n",
    "    j=0\n",
    "    dico_new={}\n",
    "    for cle , valeur in sorted(dico.items(),key=lambda x:x[1]): #ranger en ordre croissant le dico\n",
    "     \n",
    "        dico_new[cle]=valeur\n",
    "       # print(dico_new)\n",
    "                                                     #la retourner en decroissant\n",
    "    final=dict(reversed(list(dico_new.items())))     #pour avoir les # avec le + d'occurence en premier ds le dico\n",
    "   \n",
    "    while (j< K) : # affiche les k premiers elements de ce dico \n",
    "        for cle,valeur in final.items() :\n",
    "            print(cle)\n",
    "            j+=1\n",
    "            if (j==K):\n",
    "                break\n",
    "           \n",
    "       \n",
    "topK_hashtag(dico1,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateurs mentionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@ericbailly24': 1,\n",
       " '@maxigr04del': 1,\n",
       " '@isabelle170516': 1,\n",
       " '@leonna_julie': 3,\n",
       " '@Steiner2502': 1,\n",
       " '@LynLyna12': 1,\n",
       " '@miliemelo82': 1,\n",
       " '@kilianbridoux': 1,\n",
       " '@LeMeneec': 1,\n",
       " '@Polo82810715': 1,\n",
       " '@lrestistant73': 1,\n",
       " '@Pauluskupa': 1,\n",
       " '@anniemacmanus': 2,\n",
       " '@yebbasmith': 1,\n",
       " '@AzmiAnees3': 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il est mentionné'''\n",
    "liste_ment = [x for elem in liste_mentions for x in elem] \n",
    "def occurence_mention(liste):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "occurence_mention(liste_ment)\n",
    "dico2=occurence_mention(liste_ment)\n",
    "\n",
    "'''création d'un top k mention'''\n",
    "def topK_mentions(dico,K):\n",
    "    j=0\n",
    "    dico_new={}\n",
    "    for cle , valeur in sorted(dico.items(),key=lambda x:x[1]):\n",
    "        dico_new[cle]=valeur\n",
    "       \n",
    "    final=dict(reversed(list(dico_new.items())))  \n",
    "   \n",
    "    while (j< K) : \n",
    "        for cle,valeur in final.items() :\n",
    "            print(cle)\n",
    "            j+=1\n",
    "            if (j==K):\n",
    "                break\n",
    "           \n",
    "       \n",
    "topK_mentions(dico2,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1339914264522461187': 4,\n",
       " '717025418': 2,\n",
       " '992904738516717570': 4,\n",
       " '736523371': 1,\n",
       " '1471684208': 1,\n",
       " '3169236915': 2,\n",
       " '16267684': 1,\n",
       " '60117154': 1,\n",
       " '372993152': 2,\n",
       " '105241852': 1,\n",
       " '2357913366': 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il a posté un tweet'''\n",
    "def nbr_publis_utilisateur(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "nbr_publis_utilisateur(liste_auteurs)\n",
    "dico3=nbr_publis_utilisateur(liste_auteurs)\n",
    "\n",
    "'''création d'un top k utilisateurs'''\n",
    "def topK_users(dico,K):\n",
    "    j=0\n",
    "    dico_new={}\n",
    "    for cle , valeur in sorted(dico.items(),key=lambda x:x[1]):\n",
    "        dico_new[cle]=valeur\n",
    "       \n",
    "    final=dict(reversed(list(dico_new.items())))  \n",
    "   \n",
    "    while (j< K) : \n",
    "        for cle,valeur in final.items() :\n",
    "            print(cle)\n",
    "            j+=1\n",
    "            if (j==K):\n",
    "                break\n",
    "           \n",
    "       \n",
    "topK_users(dico3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'culture': 4, 'humour': 7, 'sport': 5, 'politique': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''création d'un dictionnaire contenant un topic et le nombre de fois qu'il apparait'''\n",
    "def occurence_topic(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "occurence_topic(twitts_topics)\n",
    "dico4=occurence_topic(twitts_topics)\n",
    "\n",
    "\n",
    "'''création d'un top k mention'''\n",
    "def topK_mentions(dico,K):\n",
    "    j=0\n",
    "    dico_new={}\n",
    "    for cle , valeur in sorted(dico.items(),key=lambda x:x[1]):\n",
    "        dico_new[cle]=valeur\n",
    "       \n",
    "    final=dict(reversed(list(dico_new.items())))  \n",
    "   \n",
    "    while (j< K) : \n",
    "        for cle,valeur in final.items() :\n",
    "            print(cle)\n",
    "            j+=1\n",
    "            if (j==K):\n",
    "                break\n",
    "           \n",
    "       \n",
    "topK_mentions(dico4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ensemble de tweets d’un utilisateur spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Texte': ['Goumin des éléphants joueurs la même fatigue même twitter225',\n",
       "  ' ericbailly24 maxigr04del mes tontons vous avez fait votre part JO prochain on ira en demi final au moins BRAVO à vous SupportriceMazo domie CIV',\n",
       "  'Ah oui le sommeil là sera compliqué CIV est éliminé des JO Ahi on peut faire ça ',\n",
       "  '31 juillet journée internationale de la femme africaine jifa']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweets_utilisateur():\n",
    "    #création d'un dictionnaire contenant l'identifiant de l'utilsateur\n",
    "    #comme clé et la liste de ses publications comme valuer\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    ## nous avons trouvé cette méthode sur internet\n",
    "    dico_tweets_utilisateur = df.groupby('ID').agg(lambda x: x.tolist()).to_dict('index')\n",
    "    utilisateur = input(\"entrer l'id de l'utilisateur\")\n",
    "    if utilisateur in liste_auteurs:\n",
    "        return dico_tweets_utilisateur[utilisateur]\n",
    "    #problème: si on entre 2 fois un id non valide ça ne marche pas\n",
    "    else:\n",
    "        utilisateur = input(\"cet utilisateur n'existe pas, entrer un autre id d'utilisateur\")\n",
    "        return dico_tweets_utilisateur[utilisateur]\n",
    "\n",
    "tweets_utilisateur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ensemble de tweets mentionnant un utilisateur spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    372993152\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_mention():\n",
    "    #création d'un dictionnaire contenant l'identifiant de l'utilsateur\n",
    "    #comme clé et la liste de ses publications comme valeurs\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    #print(df)\n",
    "    mention = (input(\"entrer mention\"))\n",
    "    return df['ID'][df['Texte'].str.contains(mention, regex=False)]\n",
    "\n",
    "\n",
    "find_mention()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utilisateurs mentionnant un hashtag spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    1471684208\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fonction qui renvoie les utilisateurs mentionnant un hahshtag spécifique\n",
    "##ça renvoie le texte pas les utilisateurs \n",
    "def find_hashtag ():\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    hashtag = input(\"entrer hashtag\")\n",
    "    return df['ID'][df['Texte'].str.contains(hashtag, regex=False)]\n",
    "\n",
    "find_hashtag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "530acc480c6cf79cacfe3b795deb12112f40cf157cab9e2841c7338651ce5f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
