{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecte, Traitement, et Analyse de données de réseaux sociaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du fichier Json et nettoyage du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouverture du fichier jason\n",
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "#Effacer tous les caractères spéciaux dans le texte et récupérer le texte propre dans une liste\n",
    "liste_txt =[]\n",
    "for dict in data_dict:\n",
    "    dict[\"text\"] = re.sub(r'[\\W_]+',' ', dict[\"text\"])\n",
    "    liste_txt.append(dict['text'])\n",
    "\n",
    "# Création et écriture dans le fichier zone d'atterissage\n",
    "with open(\"zone_d'atterrissage.json\", 'w') as f2:\n",
    "    json.dump(data_dict, f2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification de l'auteur de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1339914264522461187', '1339914264522461187', '1339914264522461187', '1339914264522461187', '717025418', '992904738516717570', '992904738516717570', '736523371', '1471684208', '992904738516717570', '3169236915', '992904738516717570', '16267684', '60117154', '3169236915', '372993152', '372993152', '105241852', '2357913366', '717025418']\n"
     ]
    }
   ],
   "source": [
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "liste_auteurs= []\n",
    "for dict in data:\n",
    "    liste_auteurs.append(dict['author_id'])\n",
    "print(liste_auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de la liste des hashtags et la liste des mentions de chaque publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#twitter225'], ['#SupportriceMazo', '#domie', '#CIV'], ['#CIV'], ['#jifa'], [], [], [], [], ['#versailles', '#nocturne', '#appollon'], [], [], [], [], [], [], [], [], [], [], []]\n",
      "[[], ['@ericbailly24', '@maxigr04del'], [], [], [], ['@isabelle170516', '@leonna_julie', '@Steiner2502'], ['@LynLyna12', '@leonna_julie'], [], [], ['@leonna_julie'], ['@miliemelo82', '@kilianbridoux', '@LeMeneec'], ['@Polo82810715', '@lrestistant73'], [], [], ['@Pauluskupa'], ['@anniemacmanus'], ['@yebbasmith', '@anniemacmanus'], [], ['@AzmiAnees3'], []]\n"
     ]
    }
   ],
   "source": [
    "liste_hashtags = []\n",
    "liste_mentions = []\n",
    "\n",
    "for dict in data:\n",
    "    #Extraction des hashtags\n",
    "    hashtags = re.findall(r'\\B#\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_hashtags.append(hashtags)\n",
    "    #Extraction des mentions\n",
    "    mentions = re.findall(r'\\B@\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_mentions.append(mentions)\n",
    "\n",
    "print(liste_hashtags)\n",
    "\n",
    "print(liste_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de sentiments de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "liste_sentiments = []\n",
    "with open(\"zone_d'atterrissage.json\") as f:\n",
    "   clean_data  = json.load(f)\n",
    "   \n",
    "for dico in clean_data:\n",
    "    sentiment = TextBlob(dico['text']).sentiment \n",
    "    liste_sentiments.append(sentiment[1])\n",
    "print(liste_sentiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification du/des topics de la publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['culture', 'politique', 'politique', 'culture', 'culture', 'culture', 'politique', 'culture', 'politique', 'culture', 'sport', 'sport', 'culture', 'culture', 'culture', 'culture', 'humour', 'humour', 'culture', 'sport']\n"
     ]
    }
   ],
   "source": [
    "# On va attribuer des topics aléatoirement \n",
    "liste_topics = ['sport', 'politique', 'culture', 'humour']\n",
    "twitts_topics = [rd.choice(liste_topics) for i in range(len(liste_auteurs))]\n",
    "print(twitts_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du DataFrame à exploiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploitation = pd.DataFrame(list(zip(liste_auteurs,liste_txt, liste_hashtags, liste_mentions, liste_sentiments, twitts_topics)), columns = ['ID', 'Texte','Hashtags', 'Mentions', 'Sentiments', 'Topics'])\n",
    "df_exploitation\n",
    "\n",
    "# sauvegarder notre DataFrame dans un fichier csv\n",
    "df_exploitation.to_csv(\"zone_d'exploitation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('#CIV', 2)\n",
      "('#twitter225', 1)\n",
      "('#SupportriceMazo', 1)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un hashtag et le nombre de fois qu'il apparaît\n",
    "liste_hash = [x for elem in liste_hashtags for x in elem] \n",
    "def occurence_hashtag(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "\n",
    "def topK_hashtag(dico):\n",
    "    K = int(input('entrer un entier K pour obtenir les K premiers hashtags'))\n",
    "    tuple_sorted = sorted(dico.items(), key=lambda item:item[1], reverse = True)\n",
    "    for i in range (K): \n",
    "        print(tuple_sorted[i])\n",
    "           \n",
    "topK_hashtag(occurence_hashtag(liste_hash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateurs mentionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@leonna_julie', 3)\n",
      "('@anniemacmanus', 2)\n",
      "('@ericbailly24', 1)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il est mentionné\n",
    "liste_ment = [x for elem in liste_mentions for x in elem] \n",
    "def occurence_mention(liste):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "def topK_mention(dico):\n",
    "    K = int(input('entrer un entier K pour obtenir les K premières mentions'))\n",
    "    tuple_sorted = sorted(dico.items(), key=lambda item:item[1], reverse = True)\n",
    "    for i in range (K): \n",
    "        print(tuple_sorted[i])\n",
    "           \n",
    "topK_hashtag(occurence_mention(liste_ment))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1339914264522461187', 4)\n",
      "('992904738516717570', 4)\n",
      "('717025418', 2)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il a posté un tweet\n",
    "def nbr_publis_utilisateur(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "        dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "def topK_utilisateur(dico):\n",
    "    K = int(input('entrer un entier K pour obtenir les K premiers utilisateurs'))\n",
    "    tuple_sorted = sorted(dico.items(), key=lambda item:item[1], reverse = True)\n",
    "    for i in range (K): \n",
    "        print(tuple_sorted[i])\n",
    "           \n",
    "topK_utilisateur(nbr_publis_utilisateur(liste_auteurs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('culture', 11)\n",
      "('politique', 4)\n",
      "('sport', 3)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un topic et le nombre de fois qu'il apparait\n",
    "def occurence_topic(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "def topK_topic(dico):\n",
    "    K = int(input('entrer un entier K pour obtenir les K premiers topics'))\n",
    "    tuple_sorted = sorted(dico.items(), key=lambda item:item[1], reverse = True)\n",
    "    for i in range (K): \n",
    "        print(tuple_sorted[i])\n",
    "           \n",
    "topK_hashtag(occurence_topic(twitts_topics))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ensemble de tweets d’un utilisateur spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Texte': ['Goumin des éléphants joueurs la même fatigue même twitter225',\n",
       "  ' ericbailly24 maxigr04del mes tontons vous avez fait votre part JO prochain on ira en demi final au moins BRAVO à vous SupportriceMazo domie CIV',\n",
       "  'Ah oui le sommeil là sera compliqué CIV est éliminé des JO Ahi on peut faire ça ',\n",
       "  '31 juillet journée internationale de la femme africaine jifa']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweets_utilisateur():\n",
    "    #création d'un dictionnaire contenant l'identifiant de l'utilsateur\n",
    "    #comme clé et la liste de ses publications comme valuer\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    ## nous avons trouvé cette méthode sur internet\n",
    "    dico_tweets_utilisateur = df.groupby('ID').agg(lambda x: x.tolist()).to_dict('index')\n",
    "    utilisateur = input(\"entrer l'id de l'utilisateur\")\n",
    "    if utilisateur in liste_auteurs:\n",
    "        return dico_tweets_utilisateur[utilisateur]\n",
    "    #problème: si on entre 2 fois un id non valide ça ne marche pas\n",
    "    else:\n",
    "        utilisateur = input(\"cet utilisateur n'existe pas, entrer un autre id d'utilisateur\")\n",
    "        return dico_tweets_utilisateur[utilisateur]\n",
    "\n",
    "tweets_utilisateur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ensemble de tweets mentionnant un utilisateur spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    372993152\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_mention():\n",
    "    #création d'un dictionnaire contenant l'identifiant de l'utilsateur\n",
    "    #comme clé et la liste de ses publications comme valeurs\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    #print(df)\n",
    "    mention = (input(\"entrer mention\"))\n",
    "    return df['ID'][df['Texte'].str.contains(mention, regex=False)]\n",
    "\n",
    "\n",
    "find_mention()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utilisateurs mentionnant un hashtag spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    1471684208\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fonction qui renvoie les utilisateurs mentionnant un hahshtag spécifique\n",
    "##ça renvoie le texte pas les utilisateurs \n",
    "def find_hashtag ():\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    hashtag = input(\"entrer hashtag\")\n",
    "    return df['ID'][df['Texte'].str.contains(hashtag, regex=False)]\n",
    "\n",
    "find_hashtag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représentations graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui permet de représenter les données sous forme de diagramme en bâtons\n",
    "def representation_graph(dico, couleur):\n",
    "    names = list(dico.keys())\n",
    "    values = list(dico.values())\n",
    "    plt.bar(names, values, color = couleur) ; plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Représentation graphique de l'occurence des hashtags\n",
    "representation_graph(occurence_hashtag(twitts_topics), \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Représentation graphique de l'occurence des topics\n",
    "representation_graph(occurence_topic(twitts_topics), \"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "530acc480c6cf79cacfe3b795deb12112f40cf157cab9e2841c7338651ce5f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
