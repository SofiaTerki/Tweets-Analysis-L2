{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecte, Traitement, et Analyse de données de réseaux sociaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du fichier Json et nettoyage du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouverture du fichier jason\n",
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "#Effacer tous les caractères spéciaux dans le texte et récupérer le texte propre dans une liste\n",
    "liste_txt =[]\n",
    "for dict in data_dict:\n",
    "    dict[\"text\"] = re.sub(r'[\\W_]+',' ', dict[\"text\"])\n",
    "    liste_txt.append(dict['text'])\n",
    "\n",
    "# Création et écriture dans le fichier zone d'atterissage\n",
    "with open(\"zone_d'atterrissage.json\", 'w') as f2:\n",
    "    json.dump(data_dict, f2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification de l'auteur de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1339914264522461187', '1339914264522461187', '1339914264522461187', '1339914264522461187', '717025418', '992904738516717570', '992904738516717570', '736523371', '1471684208', '992904738516717570', '3169236915', '992904738516717570', '16267684', '60117154', '3169236915', '372993152', '372993152', '105241852', '2357913366', '717025418']\n"
     ]
    }
   ],
   "source": [
    "with open('versailles_tweets_100.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "liste_auteurs= []\n",
    "for dict in data:\n",
    "    liste_auteurs.append(dict['author_id'])\n",
    "print(liste_auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de la liste des hashtags et la liste des mentions de chaque publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#twitter225'], ['#SupportriceMazo', '#domie', '#CIV'], ['#CIV'], ['#jifa'], [], [], [], [], ['#versailles', '#nocturne', '#appollon'], [], [], [], [], [], [], [], [], [], [], []]\n",
      "[[], ['@ericbailly24', '@maxigr04del'], [], [], [], ['@isabelle170516', '@leonna_julie', '@Steiner2502'], ['@LynLyna12', '@leonna_julie'], [], [], ['@leonna_julie'], ['@miliemelo82', '@kilianbridoux', '@LeMeneec'], ['@Polo82810715', '@lrestistant73'], [], [], ['@Pauluskupa'], ['@anniemacmanus'], ['@yebbasmith', '@anniemacmanus'], [], ['@AzmiAnees3'], []]\n"
     ]
    }
   ],
   "source": [
    "liste_hashtags = []\n",
    "liste_mentions = []\n",
    "\n",
    "for dict in data:\n",
    "    #Extraction des hashtags\n",
    "    hashtags = re.findall(r'\\B#\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_hashtags.append(hashtags)\n",
    "    #Extraction des mentions\n",
    "    mentions = re.findall(r'\\B@\\w*[a-zA-Z]+\\w*', dict['text'])\n",
    "    liste_mentions.append(mentions)\n",
    "\n",
    "print(liste_hashtags)\n",
    "\n",
    "print(liste_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de sentiments de la publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "liste_sentiments = []\n",
    "with open(\"zone_d'atterrissage.json\") as f:\n",
    "   clean_data  = json.load(f)\n",
    "   \n",
    "for dico in clean_data:\n",
    "    sentiment = TextBlob(dico['text']).sentiment \n",
    "    liste_sentiments.append(sentiment[1])\n",
    "print(liste_sentiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification du/des topics de la publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['culture', 'humour', 'humour', 'sport', 'politique', 'politique', 'culture', 'humour', 'culture', 'sport', 'politique', 'sport', 'humour', 'humour', 'politique', 'humour', 'sport', 'humour', 'sport', 'culture']\n"
     ]
    }
   ],
   "source": [
    "# On va attribuer des topics aléatoirement \n",
    "liste_topics = ['sport', 'politique', 'culture', 'humour']\n",
    "twitts_topics = [rd.choice(liste_topics) for i in range(len(liste_auteurs))]\n",
    "print(twitts_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du DataFrame à exploiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Texte</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>Goumin des éléphants joueurs la même fatigue m...</td>\n",
       "      <td>[#twitter225]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>ericbailly24 maxigr04del mes tontons vous ave...</td>\n",
       "      <td>[#SupportriceMazo, #domie, #CIV]</td>\n",
       "      <td>[@ericbailly24, @maxigr04del]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>Ah oui le sommeil là sera compliqué CIV est él...</td>\n",
       "      <td>[#CIV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>31 juillet journée internationale de la femme ...</td>\n",
       "      <td>[#jifa]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717025418</td>\n",
       "      <td>Le pedigree https t co D3Rv7A2BOF</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>isabelle170516 leonna julie Steiner2502 Vous ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@isabelle170516, @leonna_julie, @Steiner2502]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>LynLyna12 leonna julie La grande muette conti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@LynLyna12, @leonna_julie]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>736523371</td>\n",
       "      <td>Under wsh</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1471684208</td>\n",
       "      <td>Les bains d apollon versailles nocturne appoll...</td>\n",
       "      <td>[#versailles, #nocturne, #appollon]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>leonna julie Le rdv aujourd hui aura tenu ses...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@leonna_julie]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3169236915</td>\n",
       "      <td>miliemelo82 kilianbridoux LeMeneec il est tem...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@miliemelo82, @kilianbridoux, @LeMeneec]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>Polo82810715 lrestistant73 Un mouton c est bi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@Polo82810715, @lrestistant73]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16267684</td>\n",
       "      <td>I m at Gardens of Versailles in Versailles Île...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60117154</td>\n",
       "      <td>Jungle Cruise https t co JyM8WQjz4p UGC Cyrano...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3169236915</td>\n",
       "      <td>Pauluskupa</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@Pauluskupa]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>372993152</td>\n",
       "      <td>anniemacmanus legend</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@anniemacmanus]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>372993152</td>\n",
       "      <td>yebbasmith anniemacmanus</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@yebbasmith, @anniemacmanus]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>105241852</td>\n",
       "      <td>Vient de publier une photo à Quelquepart https...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2357913366</td>\n",
       "      <td>AzmiAnees3 He was my lover s accomplice</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@AzmiAnees3]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>717025418</td>\n",
       "      <td>Le gardien lui parle non https t co e3WewDSQOJ</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                              Texte  \\\n",
       "0   1339914264522461187  Goumin des éléphants joueurs la même fatigue m...   \n",
       "1   1339914264522461187   ericbailly24 maxigr04del mes tontons vous ave...   \n",
       "2   1339914264522461187  Ah oui le sommeil là sera compliqué CIV est él...   \n",
       "3   1339914264522461187  31 juillet journée internationale de la femme ...   \n",
       "4             717025418                  Le pedigree https t co D3Rv7A2BOF   \n",
       "5    992904738516717570   isabelle170516 leonna julie Steiner2502 Vous ...   \n",
       "6    992904738516717570   LynLyna12 leonna julie La grande muette conti...   \n",
       "7             736523371                                         Under wsh    \n",
       "8            1471684208  Les bains d apollon versailles nocturne appoll...   \n",
       "9    992904738516717570   leonna julie Le rdv aujourd hui aura tenu ses...   \n",
       "10           3169236915   miliemelo82 kilianbridoux LeMeneec il est tem...   \n",
       "11   992904738516717570   Polo82810715 lrestistant73 Un mouton c est bi...   \n",
       "12             16267684  I m at Gardens of Versailles in Versailles Île...   \n",
       "13             60117154  Jungle Cruise https t co JyM8WQjz4p UGC Cyrano...   \n",
       "14           3169236915                                        Pauluskupa    \n",
       "15            372993152                              anniemacmanus legend    \n",
       "16            372993152                          yebbasmith anniemacmanus    \n",
       "17            105241852  Vient de publier une photo à Quelquepart https...   \n",
       "18           2357913366           AzmiAnees3 He was my lover s accomplice    \n",
       "19            717025418     Le gardien lui parle non https t co e3WewDSQOJ   \n",
       "\n",
       "                               Hashtags  \\\n",
       "0                         [#twitter225]   \n",
       "1      [#SupportriceMazo, #domie, #CIV]   \n",
       "2                                [#CIV]   \n",
       "3                               [#jifa]   \n",
       "4                                    []   \n",
       "5                                    []   \n",
       "6                                    []   \n",
       "7                                    []   \n",
       "8   [#versailles, #nocturne, #appollon]   \n",
       "9                                    []   \n",
       "10                                   []   \n",
       "11                                   []   \n",
       "12                                   []   \n",
       "13                                   []   \n",
       "14                                   []   \n",
       "15                                   []   \n",
       "16                                   []   \n",
       "17                                   []   \n",
       "18                                   []   \n",
       "19                                   []   \n",
       "\n",
       "                                          Mentions  Sentiments     Topics  \n",
       "0                                               []         0.0    culture  \n",
       "1                    [@ericbailly24, @maxigr04del]         1.0     humour  \n",
       "2                                               []         0.0     humour  \n",
       "3                                               []         0.0      sport  \n",
       "4                                               []         0.0  politique  \n",
       "5   [@isabelle170516, @leonna_julie, @Steiner2502]         1.0  politique  \n",
       "6                      [@LynLyna12, @leonna_julie]         0.0    culture  \n",
       "7                                               []         0.0     humour  \n",
       "8                                               []         0.0    culture  \n",
       "9                                  [@leonna_julie]         0.0      sport  \n",
       "10       [@miliemelo82, @kilianbridoux, @LeMeneec]         0.0  politique  \n",
       "11                 [@Polo82810715, @lrestistant73]         0.9      sport  \n",
       "12                                              []         0.0     humour  \n",
       "13                                              []         0.0     humour  \n",
       "14                                   [@Pauluskupa]         0.0  politique  \n",
       "15                                [@anniemacmanus]         0.0     humour  \n",
       "16                   [@yebbasmith, @anniemacmanus]         0.0      sport  \n",
       "17                                              []         0.0     humour  \n",
       "18                                   [@AzmiAnees3]         0.0      sport  \n",
       "19                                              []         0.0    culture  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploitation = pd.DataFrame(list(zip(liste_auteurs,liste_txt, liste_hashtags, liste_mentions, liste_sentiments, twitts_topics)), columns = ['ID', 'Texte','Hashtags', 'Mentions', 'Sentiments', 'Topics'])\n",
    "df_exploitation\n",
    "\n",
    "# sauvegarder notre DataFrame dans un fichier csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#twitter225': 1,\n",
       " '#SupportriceMazo': 1,\n",
       " '#domie': 1,\n",
       " '#CIV': 2,\n",
       " '#jifa': 1,\n",
       " '#versailles': 1,\n",
       " '#nocturne': 1,\n",
       " '#appollon': 1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un hashtag et le nombre de fois qu'il apparaît\n",
    "liste_hash = [x for elem in liste_hashtags for x in elem] \n",
    "def occurence_hashtag(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "occurence_hashtag(liste_hash)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateurs mentionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@ericbailly24': 1,\n",
       " '@maxigr04del': 1,\n",
       " '@isabelle170516': 1,\n",
       " '@leonna_julie': 3,\n",
       " '@Steiner2502': 1,\n",
       " '@LynLyna12': 1,\n",
       " '@miliemelo82': 1,\n",
       " '@kilianbridoux': 1,\n",
       " '@LeMeneec': 1,\n",
       " '@Polo82810715': 1,\n",
       " '@lrestistant73': 1,\n",
       " '@Pauluskupa': 1,\n",
       " '@anniemacmanus': 2,\n",
       " '@yebbasmith': 1,\n",
       " '@AzmiAnees3': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il est mentionné\n",
    "liste_ment = [x for elem in liste_mentions for x in elem] \n",
    "def occurence_mention(liste):\n",
    "    occurences = []\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "\n",
    "occurence_mention(liste_ment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1339914264522461187': 4,\n",
       " '717025418': 2,\n",
       " '992904738516717570': 4,\n",
       " '736523371': 1,\n",
       " '1471684208': 1,\n",
       " '3169236915': 2,\n",
       " '16267684': 1,\n",
       " '60117154': 1,\n",
       " '372993152': 2,\n",
       " '105241852': 1,\n",
       " '2357913366': 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un utilisateur et le nombre de fois qu'il a posté un tweet\n",
    "def nbr_publis_utilisateur(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "nbr_publis_utilisateur(liste_auteurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'culture': 4, 'humour': 7, 'sport': 5, 'politique': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création d'un dictionnaire contenant un topic et le nombre de fois qu'il apparait\n",
    "def occurence_topic(liste):\n",
    "    dic = {}\n",
    "    for i in range (len(liste)):\n",
    "            dic[liste[i]] = liste.count(liste[i]) \n",
    "    return dic\n",
    "\n",
    "occurence_topic(twitts_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ensemble de tweets d’un utilisateur spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Texte': ['Goumin des éléphants joueurs la même fatigue même twitter225',\n",
       "  ' ericbailly24 maxigr04del mes tontons vous avez fait votre part JO prochain on ira en demi final au moins BRAVO à vous SupportriceMazo domie CIV',\n",
       "  'Ah oui le sommeil là sera compliqué CIV est éliminé des JO Ahi on peut faire ça ',\n",
       "  '31 juillet journée internationale de la femme africaine jifa']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweets_utilisateur():\n",
    "    #création d'un dictionnaire contenant l'identifiant de l'utilsateur\n",
    "    #comme clé et la liste de ses publications comme valuer\n",
    "    df = df_exploitation[[\"ID\", \"Texte\"]]\n",
    "    ## nous avons trouvé cette méthode sur internet\n",
    "    dico_tweets_utilisateur = df.groupby('ID').agg(lambda x: x.tolist()).to_dict('index')\n",
    "    utilisateur = input(\"entrer l'id de l'utilisateur\")\n",
    "    if utilisateur in liste_auteurs:\n",
    "        return dico_tweets_utilisateur[utilisateur]\n",
    "    #problème: si on entre 2 fois un id non valide ça ne marche pas\n",
    "    else:\n",
    "        utilisateur = input(\"cet utilisateur n'existe pas, entrer un autre id d'utilisateur\")\n",
    "        return dico_tweets_utilisateur[utilisateur]\n",
    "\n",
    "tweets_utilisateur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ensemble de tweets mentionnant un utilisateur spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_list_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no results",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2609/687728120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdico_tweets_mentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmention\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtweets_mention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2609/687728120.py\u001b[0m in \u001b[0;36mtweets_mention\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_exploitation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Mentions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Texte\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m## nous avons trouvé cette méthode sur internet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdico_tweets_mentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mentions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entrer l'utilisateur mentionné\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmention\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mliste_mentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m                         \u001b[0;31m# raised directly by _aggregate_multiple_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_frame\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;31m# test_pass_args_kwargs_duplicate_columns gets here with non-unique columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m                 \u001b[0mfres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mget_iterator\u001b[0;34m(self, data, axis)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \"\"\"\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_keys_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_splitter\u001b[0;34m(self, data, axis)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mGenerator\u001b[0m \u001b[0myielding\u001b[0m \u001b[0msubsetted\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \"\"\"\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mgroup_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroup_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mcomp_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_group_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compressed_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0mping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mcodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codes_and_uniques\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;31m# error: Incompatible types in assignment (expression has type \"Union[\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;31m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             codes, uniques = algorithms.factorize(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    693\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouping_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         codes, uniques = factorize_array(\n\u001b[0m\u001b[1;32m    819\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/l1-python/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     uniques, codes = table.factorize(\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "def tweets_mention():\n",
    "    #création d'un dictionnaire contenant l'identifiant de l'utilsateur\n",
    "    #comme clé et la liste de ses publications comme valuer\n",
    "    df = df_exploitation[[\"Mentions\", \"Texte\"]]\n",
    "    ## nous avons trouvé cette méthode sur internet\n",
    "    dico_tweets_mentions = df.groupby('Mentions').agg(lambda x: x.tolist()).to_dict('index')\n",
    "    mention = input(\"entrer l'utilisateur mentionné\")\n",
    "    if mention in liste_mentions:\n",
    "        return dico_tweets_mentions[mention]\n",
    "    #problème: si on entre 2 fois un id non valide ça ne marche pas\n",
    "    else:\n",
    "        mention = input(\"cet mention n'existe pas, entrer un autre utilisateur mentionné\")\n",
    "        return dico_tweets_mentions[mention]\n",
    "\n",
    "tweets_mention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utilisateurs mentionnant un hashtag spécifique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "530acc480c6cf79cacfe3b795deb12112f40cf157cab9e2841c7338651ce5f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
